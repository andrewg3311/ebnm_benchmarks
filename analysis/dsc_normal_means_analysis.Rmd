---
title: "Normal Means DSC Analysis"
author: "Andrew Goldstein"
date: "October 30, 2018"
output:
  workflowr::wflow_html:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, error = T, warning = T, message = F, collapse = T, comment = "#", results = 'hold', fig.align = 'center', fig.height = 8)
```

# Introduction
This code analyzes the results of the DSC replications. Currently, only the `point_normal` prior is tested. 

The `point_normal` prior assumes
$$
\begin{aligned}
\theta_j \stackrel{iid}{\sim} \pi_0 \delta_\mu + (1 - \pi_0)\mathcal{N}\Big(\mu, \frac1a\Big) \\
x_j \stackrel{\perp}{\sim} \mathcal{N}\Big(\theta_j, s_j^2\Big)
\end{aligned}
$$
By setting $\mu := 0$, we can recover the case where there is a point-mass at 0. By setting $\pi_0 := 0$, we can recover the case where there is no point-mass.

# Analysis
```{r}
# Load required packages
library(dscrutils)
library(dplyr)
library(tidyr)
library(ggplot2)

# load and reshape data
dscout = dscquery(dsc.outdir = "./code/dsc-normalmeans/normal_means", 
                  targets = c("simulate.true_pi0", "simulate.true_a", "simulate.true_mu", 
                              "eb.prior", "eb.fix_mu", "eb.g_pi0", "eb.g_a", "eb.g_mu", 
                              "eb.loglik", "score.RMSE"))

dscout_wide = dscout %>% spread(score, score.RMSE)
View(dscout_wide)
```
We replicate 10 times for all combinations of parameter values: $\mu \in \{0\}$, $\pi_0 \in \{0, .2, .5, .8, 1\}$, $a \in \{1/25, 1/16, 1/4\}$, and we try both estimating $\mu$ and fixing $\mu = 0$. The standard errors $s_j$ were all set to 1.

## Parameter Estimation
In this section, we investigate our ability to recover the parameter values.

Figures 1-3 below show our attempts at recovering $a$, $\pi_0$, and $\mu$, respectively. For figures 1-2, the top and bottom rows separate between the cases when $\mu$ was fixed at 0 (bottom) or estimated (top). For figure 3, only the cases where $\mu$ was estimated are shown.
```{r}
labels_pi0 = character(length(unique(dscout_wide$simulate.true_pi0)))
for (i in 1:length(labels_pi0)) {
  labels_pi0[i] = paste("pi0 = ", unique(dscout_wide$simulate.true_pi0)[i], sep = "")
  names(labels_pi0)[i] = unique(dscout_wide$simulate.true_pi0)[i]
}
labels_a = character(length(unique(dscout_wide$simulate.true_a)))
for (i in 1:length(labels_a)) {
  labels_a[i] = paste("a = ", unique(dscout_wide$simulate.true_a)[i], sep = "")
  names(labels_a)[i] = unique(dscout_wide$simulate.true_a)[i]
}
labels_fix_mu = character(length(unique(dscout_wide$eb.fix_mu)))
for (i in 1:length(labels_fix_mu)) {
  labels_fix_mu[i] = paste("fix_mu = ", unique(dscout_wide$eb.fix_mu)[i], sep = "")
  names(labels_fix_mu)[i] = unique(dscout_wide$eb.fix_mu)[i]
}

ggplot(dscout_wide, aes(x = factor(simulate.true_a), y = eb.g_a)) +
  geom_boxplot() + facet_grid(eb.fix_mu ~ simulate.true_pi0, labeller = labeller(simulate.true_pi0 = labels_pi0, eb.fix_mu = labels_fix_mu)) +
  ggtitle("Figure 1: Recovering precision a") + xlab("True a") + ylab ("Estimated a")


ggplot(dscout_wide, aes(x = factor(simulate.true_pi0), y = eb.g_pi0)) +
  geom_boxplot() + facet_grid(eb.fix_mu ~ simulate.true_a, labeller = labeller(simulate.true_a = labels_a, eb.fix_mu = labels_fix_mu))+ 
  ggtitle("Figure 2: Recovering null component pi0") + xlab("True pi0") + ylab ("Estimated pi0")


ggplot(filter(dscout_wide, eb.fix_mu == 0), aes(x = factor(simulate.true_mu), y = eb.g_mu)) +
  geom_boxplot() + facet_grid(simulate.true_pi0 ~ simulate.true_a, labeller = labeller(simulate.true_a = labels_a, simulate.true_pi0 = labels_pi0)) +
  ggtitle("Figure 3: Recovering mean mu") + xlab("True mu") + ylab ("Estimated mu")
```

From these plots, a few things become apparent. First, for larger values of $\pi_0$, our estimates of $a$ become highly inaccurate and extremely inflated. This is due to the estimated $\widehat{\pi_0}$ being very slightly smaller than 1, which can result in inflated values of $a$. I recommend that we add a check for this condition.

Second, for larger precisions (i.e. our non-null component is more concentrated near its mean), our estimation of $\pi_0$ becomes inaccurate very quickly. Some further testing could be beneficial to test at what signal-to-noise ratios this method is reliable.

Third, when estimating $\pi_0$, simultaneously estimating $\mu$ can lead to more accurate estimates of $\pi_0$, but can also be anti-conservative. In contrast, fixing $\mu$ is often conservative in its estimates when the signal-to-noise ratio is small.

Fourth, when estimating $\mu$, the method appears to return sensible estimates.

## RMSE of Estimating Effects $\theta_j$
In this section, we look at the RMSEs of estimating the true effects, $\theta_j$, using the posterior means supplied by the `ebnm` function.

Figure 4 below plots the RMSEs for all combinations of $\pi_0$, $a$, and whether or not we fixed $\mu := 0$.
```{r}
ggplot(dscout_wide, aes(x = factor(eb.fix_mu), y = score_theta)) +
  geom_boxplot() + facet_grid(simulate.true_pi0 ~ simulate.true_a, labeller = labeller(simulate.true_a = labels_a, simulate.true_pi0 = labels_pi0)) +
  ggtitle("Figure 4: Estimating Effects") + xlab("Fix_mu") + ylab ("RMSE")
```
We can see that fixing $\mu := 0$ doesn't have much of an effect on the RMSE (with the obvious exception of when all effects are null, so our RMSE is 0). As expected, the RMSE is inversely related to $\pi_0$, and inversely related to $a$.

However, most cases have RMSEs well over 1, which is the expected RMSE for simply using $x_j$ for $\widehat{\theta_j}$ (since $x_j \sim \mathcal{N}(\theta_j, 1^2))$.

## Log-Likelihoods
In this section, we look at the log-likelihoods returned from the `ebnm` function.

Figure 5 below plots the log-likelihoods for all combinations of $\pi_0$, $a$, and whether or not we fixed $\mu := 0$.
```{r}
ggplot(dscout_wide, aes(x = factor(eb.fix_mu), y = eb.loglik)) +
  geom_boxplot() + facet_grid(simulate.true_pi0 ~ simulate.true_a, labeller = labeller(simulate.true_a = labels_a, simulate.true_pi0 = labels_pi0)) +
  ggtitle("Figure 5: Log-Likelihoods") + xlab("Fix_mu") + ylab ("log-likelihood")
```
We can see that estimating $\mu$ has little to no effect on the resulting log-likelihood.

