---
title: "EBNM Benchmarking"
author: "Andrew Goldstein"
date: "October 16, 2018"
output:
  workflowr::wflow_html:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, error = T, warning = T, message = F, results = 'asis', fig.align = 'center')
```

# Introduction
This code executes the functions in the `ebnm` package on simulated data. We simulate data according to different generating processes, and test the speed and accuracy of `ebnm_normal`, `ebnm_point_normal`, and `ebnm_point_laplace` functions.

```{r}
# Load required packages
library(workflowr)
library(microbenchmark)
library(dplyr)
library(RColorBrewer)
devtools::load_all("../ebnm")
```

Note that, in the implementation for comparing different settings/functions, if the estimated value for $\hat{a}$ is extreme, it is not included in some plots, but a warning message will warn the user about their existence.
```{r}
# This function simulates data from the ebnm (point) normal problem. It generates 1/s_j^2 randomly from a Gamma(s_alpha, s_beta) distribution
sim_ebnm_normal_data = function(n, mu, a, pi0, s_alpha, s_beta) {
  if ((mu != 0) & (pi0 > 0)) { # if trying to simulate from point-normal w/ mu != 0
    stop("If using point-normal prior, mu must be set to 0")
  }
  
  theta = rnorm(n, mean = mu, sd = sqrt(1/a))
  nonnulls = rbinom(n, size = 1, prob = 1 - pi0)
  theta = theta * nonnulls # change to 0 if null
  t = rgamma(n, shape = s_alpha, rate = s_beta) # 1/s_j^2
  s = sqrt(1 / t)
  x = rnorm(n, mean = theta, sd = s)
  return(list(x = x, s = s, theta = theta))
}

# Function to calculate results
calc_res = function(ebnm_fn, x, s, theta, g_start = NULL) {
  ebnm_res = ebnm_fn(x, s, g = g_start)
  par1 = ebnm_res$fitted_g[[1]] # mu for normal, pi0 for point-normal
  par2 = ebnm_res$fitted_g[[2]] # a for normal, a for point-normal
  MSE = mean((ebnm_res$result$PosteriorMean - theta)^2)
  ll = ebnm_res$loglik
  return(c(par1, par2, MSE, ll))
}



# This function simulates data B times, each time calculating the total computation time, the estimated values for mu and a, the MSE of the posterior mean in trying to recover theta, and the loglikelihood. Different starting values can be manually specified
# benchmark_name should be used when comparing different benchmark results
benchmark_ebnm_normal = function(ebnm_fn, B = 1000, n = 1000, mu = 0, a = 1/16, pi0 = 0, s_alpha = 2, s_beta = 10, g_start = NULL, bench_times = 5, bench_name = "", seed = 1138) {
  set.seed(seed)
  
  par_names = names(ebnm_fn(c(1,1), c(1, 1))$fitted_g) # c("mu", "a") or c("pi0", "a")
  
  res = data.frame(avg_time = numeric(B), par1 = numeric(B), par2 = numeric(B), MSE = numeric(B), ll = numeric(B))
  colnames(res)[grepl("^par[0-9]$", colnames(res))] = par_names
  
  for (i in 1:B) {
    xst = sim_ebnm_normal_data(n, mu, a, pi0, s_alpha, s_beta) # simulate data
    x = xst$x
    s = xst$s
    theta = xst$theta
    
    m = microbenchmark(ebnm_fn(x, s), times = bench_times)
    res[i, 1] = mean(m$time / 1e6) # milliseconds
    res[i, 2:5] = calc_res(ebnm_fn, x, s, theta, g_start)
  }
  
  res$name = bench_name
  return(res)
}


# This function takes a list of result dataframes, true parameter values. It plots comparisons of the different runs
# These should all have been run with the same parameter values, same seed, etc for consistency
compare_res = function(res_list, true_par1, true_par2) {
  n = length(res_list)
  cols = brewer.pal(n, "Dark2")[1:n]
  res_df = bind_rows(res_list)
  par_names = colnames(res_df)[2:3]
  
  # make sure boxplots are in correct order
  lvl = levels(as.factor(res_df$name))
  names(lvl) = lvl
  res_df$name_factor = factor(res_df$name, levels = lvl[unique(res_df$name)])
  
  # Avg Time
  boxplot(avg_time ~ name_factor, data = res_df, ylab = "Average Runtime (milliseconds)", main = "Comparison of Average Runtimes", xaxt = "n", xlab = "", outlne = F)
  points(jitter(as.numeric(res_df$name_factor)), res_df$avg_time, col = rep(cols, times = sapply(res_list, nrow)))
  axis(1, labels = F, tick = F)
  text(x =  seq_along(unique(res_df$name)), y = par("usr")[3], srt = 45, adj = 1, labels = unique(res_df$name), xpd = T)
  
  # MSE
  boxplot(MSE ~ name_factor, data = res_df, ylab = "MSE", main = "Comparison of MSEs", xaxt = "n", xlab = "", outlne = F)
  points(jitter(as.numeric(res_df$name_factor)), res_df$MSE, col = rep(cols, times = sapply(res_list, nrow)))
  axis(1, labels = F, tick = F)
  text(x =  seq_along(unique(res_df$name)), y = par("usr")[3], srt = 45, adj = 1, labels = unique(res_df$name), xpd = T)
  
  # log-lik
  boxplot(ll ~ name_factor, data = res_df, ylab = "Log-Likelihood", main = "Comparison of Log-Likelihoods", xaxt = "n", xlab = "", outlne = F)
  points(jitter(as.numeric(res_df$name_factor)), res_df$ll, col = rep(cols, times = sapply(res_list, nrow)))
  axis(1, labels = F, tick = F)
  text(x =  seq_along(unique(res_df$name)), y = par("usr")[3], srt = 45, adj = 1, labels = unique(res_df$name), xpd = T)
  
  # par1 (pi0 or mu)
  ## all on one plot
  
  d = res_list[[1]][, par_names[1]]
  try({
    plot(density(d), xlab = paste("MLE Estimate for ", par_names[1], sep = ""), main = paste("Density of Estimates for ", par_names[1], sep = ""), col = cols[1], xlim = range(res_df[, par_names[1]], finite = T) , ylim = c(0, min(10, 1.1 * max(density(d)$y))), lwd = 2)
  })
  for (i in 2:n) {
    try({
      d = res_list[[i]][, par_names[1]]
      lines(density(d), col = cols[i], lwd = 2)
    })
  }
  try({
    abline(v = true_par1, col = "red")
    legend("topright", legend = c(unique(res_df$name), "Truth"), fill = c(cols, "red"), bty = "n")
  })
  
  ## all on different plots
  for (i in 1:n) {
    try({
        d = res_list[[i]][, par_names[1]]
        hist(d, xlab = paste("MLE Estimate for ", par_names[1], sep = ""), main = paste("Estimates for ", par_names[1], ": run ", unique(res_list[[i]]$name), sep = ""))
        abline(v = true_par1, col = "red")
    })
  }
  
  # par2 (a)
  ## all on one plot
  d = res_list[[1]][, par_names[2]]
  plot_ind = (abs(d - true_par2) / true_par2 <= 2)
  try({
    plot(density(d[plot_ind]), xlab = paste("MLE Estimate for ", par_names[2], sep = ""), main = paste("Density of Estimates for ", par_names[2], sep = ""), col = cols[1], xlim = range(res_df[, par_names[2]], finite = T), ylim = c(0, min(10, 1.1 * max(density(d[plot_ind])$y))), lwd = 2)
    if (sum(!plot_ind) > 1) { # if relative error > 200%
      warning(paste("Some fitted values for ", par_names[2], " in run ", unique(res_list[[1]]$name), " were very far from the true value. These should be inspected more closely", sep = ""))
    }
  })
  for (i in 2:n) {
    try({
      d = res_list[[i]][, par_names[2]]
      plot_ind = (abs(d - true_par2) / true_par2 <= 2)
      lines(density(d[plot_ind]), col = cols[i], lwd = 2)
      if (sum(!plot_ind) > 1) { # if relative error > 200%
        warning(paste("Some fitted values for ", par_names[2], " in run ", unique(res_list[[i]]$name), " were very far from the true value. These should be inspected more closely", sep = ""))
      }
    })

    #if (sum(plot_ind)) ADD CONDITION THAT IF TOO MANY ARE BAD, SKIP AND GIVE WARNING
  }
  try({
    abline(v = true_par2, col = "red")
    legend("topright", legend = c(unique(res_df$name), "Truth"), fill = c(cols, "red"), bty = "n")
  })
  
    ## all on different plots
  for (i in 1:n) {
    try({
      d = res_list[[i]][, par_names[2]]
      hist(d, xlab = paste("MLE Estimate for ", par_names[2], sep = ""), main = paste("Estimates for ", par_names[2], ": run ", unique(res_list[[i]]$name), sep = ""))
      abline(v = true_par2, col = "red")
    })
  }
}
```


# `ebnm_normal` Testing
In this section, we test the `ebnm_normal` function. This function assumes that data are generated from the following model:
$$
\begin{aligned}
\theta_j \stackrel{iid}{\sim} \mathcal{N}\Big(\mu, \frac1a\Big) \\
x_j \stackrel{\perp}{\sim} \mathcal{N}\Big(\theta_j, s_j^2\Big)
\end{aligned}
$$
The $x_j$ and $s_j$ are supplied to the `enbm_normal` function, which then finds the MLE estimates $\hat{\mu}$ and $\hat{a}$ and provides posterior estimates for the first and second moments of $\theta_j$.

Here, I simulate data from the above distribution and test the speed and accuracy at different starting points for the optimization problem.
```{r}
mu = 0
a = 1/16
s_alpha = 2
s_beta = 10
```
The true value for $\mu$ is `r mu`, and the true value for $a$ is `r a`.

## Simulation Study Results
The plots below detail the results of the simulation study. For each of $B = 100$ simulation repetitions, I simulate $n = 1000$ observations $x_j$ from the normal means model, where $1 / s_j^2$ are simulated randomly from a Gamma(`r s_alpha`, `r s_beta`) distribution.

```{r}
res_list_normal = list(benchmark_ebnm_normal(ebnm_fn = ebnm_normal, B=100, bench_name = "Default Start", mu = mu, a = a, s_alpha = s_alpha, s_beta = s_beta), 
                benchmark_ebnm_normal(ebnm_fn = ebnm_normal, B=100, g_start = list(mu = mu, a = a), bench_name = "(mu, a) Start", mu = mu, a = a, s_alpha = s_alpha, s_beta = s_beta),
                benchmark_ebnm_normal(ebnm_fn = ebnm_normal, B=100, g_start = list(mu = 1, a = 1), bench_name = "(1, 1) Start", mu = mu, a = a, s_alpha = s_alpha, s_beta = s_beta), 
                benchmark_ebnm_normal(ebnm_fn = ebnm_normal, B=100, g_start = list(mu = -1, a = 1), bench_name = "(-1, 1) Start", mu = mu, a = a, s_alpha = s_alpha, s_beta = s_beta), 
                benchmark_ebnm_normal(ebnm_fn = ebnm_normal, B=100, g_start = list(mu = 100, a = a), bench_name = "(100, a) Start", mu = mu, a = a, s_alpha = s_alpha, s_beta = s_beta), 
                benchmark_ebnm_normal(ebnm_fn = ebnm_normal, B=100, g_start = list(mu = 0, a = 100), bench_name = "(mu, 100) Start", mu = mu, a = a, s_alpha = s_alpha, s_beta = s_beta))

compare_res(res_list_normal, mu, a)
```

## Analysis of Results
This section characterizes the reults from the simulation study.

### Run-Times
As we can see from the first plot, the starting values for the parameters don't affect run-times too much, with one exception where the default time was considerably slower than the rest.

### Estimated Parameter Model Performance
The second and third plots compare the MSEs in recovering the effects, as well as the log-likelihoods obtained from the estimated parameters. We can see that the starting values only have a significant effect on the outcome when the starting value for the mean, $\mu$, is very far from the true value of `r mu`.

### Parameter Estimation
The remaining plots show the distributions of the posterior means for our parameters $\mu$ and $a$. The vertical red lines indicate the true value used to generate the data.

We can see that the method performs adequately well in recovering the mean $\mu$ and precision $a$ under all starting values for our parameters, with the exception of when the starting value for $\mu$ is far from the truth (note the warning below the plot for estimating $\mu$ with these starting values).

# `ebnm_point_normal` Testing
In this section, we test the `ebnm_point_normal` function. This function assumes that data are generated from the following model:
$$
\begin{aligned}
\theta_j \stackrel{iid}{\sim} \pi_0 \delta_0 + (1 - \pi_0)\mathcal{N}\Big(0, \frac1a\Big) \\
x_j \stackrel{\perp}{\sim} \mathcal{N}\Big(\theta_j, s_j^2\Big)
\end{aligned}
$$
The $x_j$ and $s_j$ are supplied to the `enbm_point_normal` function, which then finds the MLE estimates $\hat{\pi_0}$ and $\hat{a}$ and provides posterior estimates for the first and second moments of $\theta_j$.

Here, I simulate data from the above distribution and test the speed and accuracy at different starting points for the optimization problem. 
```{r}
pi0 = .8
a = 1/16
s_alpha = 2
s_beta = 10
```
The true value for $\pi_0$ is `r pi0`, and the true value for $a$ is `r a`.

## Simulation Study Results
The plots below detail the results of the simulation study. For each of $B = 100$ simulation repetitions, I simulate $n = 1000$ observations $x_j$ from the point normal means model, where $1 / s_j^2$ are simulated randomly from a Gamma(`r s_alpha`, `r s_beta`) distribution.

```{r}
res_list_point_normal = list(benchmark_ebnm_normal(ebnm_fn = ebnm_point_normal, B=100, bench_name = "Default Start", pi0 = pi0, a = a, s_alpha = s_alpha, s_beta = s_beta), 
                benchmark_ebnm_normal(ebnm_fn = ebnm_point_normal, B=100, g_start = list(pi0 = pi0, a = a), bench_name = "(pi0, a) Start", pi0 = pi0, a = a, s_alpha = s_alpha, s_beta = s_beta),
                benchmark_ebnm_normal(ebnm_fn = ebnm_point_normal, B=100, g_start = list(pi0 = 1, a = a), bench_name = "(1, a) Start", pi0 = pi0, a = a, s_alpha = s_alpha, s_beta = s_beta), 
                benchmark_ebnm_normal(ebnm_fn = ebnm_point_normal, B=100, g_start = list(pi0 = 0, a = a), bench_name = "(0, a) Start", pi0 = pi0, a = a, s_alpha = s_alpha, s_beta = s_beta), 
                benchmark_ebnm_normal(ebnm_fn = ebnm_point_normal, B=100, g_start = list(pi0 = pi0, a = 1e-5), bench_name = "(pi0, 1e-5) Start", pi0 = pi0, a = a, s_alpha = s_alpha, s_beta = s_beta), 
                benchmark_ebnm_normal(ebnm_fn = ebnm_point_normal, B=100, g_start = list(pi0 = pi0, a = 50), bench_name = "(pi0, 50) Start", pi0 = pi0, a = a, s_alpha = s_alpha, s_beta = s_beta))

compare_res(res_list_point_normal, pi0, a)
```

## Analysis of Results
This section characterizes the reults from the simulation study.

### Run-Times
As we can see from the first plot, the starting values for the parameters don't affect run-times too much, with one exception where the default time was considerably slower than the rest.

### Estimated Parameter Model Performance
The second and third plots compare the MSEs in recovering the effects, as well as the log-likelihoods obtained from the estimated parameters. We can see that the starting values only have a significant effect on the outcome when the starting value for the precision, $a$, is much smaller than the true value `r a`.

### Parameter Estimation
The remaining plots show the distributions of the posterior means for our parameters $\pi_0$ and $a$. The vertical red lines indicate the true value used to generate the data.

We can see that the method performs adequately well in recovering the null proportion $\pi_0$ and precision $a$ under all starting values for our parameters, with the exception of when our starting value for $a$ is much smaller than the true value.
